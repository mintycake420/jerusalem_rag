{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jerusalem RAG Explorer - Complete Demo\n",
        "\n",
        "## A Retrieval-Augmented Generation System for Crusader History Research\n",
        "\n",
        "**By Yotam Nachtomy-Katz**  \n",
        "**ID: 211718366**  \n",
        "**Submitted: 01.02.26**  \n",
        "**Course: Information Retrieval**  \n",
        "**Haifa University**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook provides a complete demonstration of the Jerusalem RAG Explorer system, from data ingestion to question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Project Overview](#1-project-overview)\n",
        "2. [System Architecture](#2-system-architecture)\n",
        "3. [Setup](#3-setup)\n",
        "4. [Data Pipeline Demo](#4-data-pipeline-demo)\n",
        "5. [Retrieval Demo](#5-retrieval-demo)\n",
        "6. [Question Answering Demo](#6-question-answering-demo)\n",
        "7. [Response Modes](#7-response-modes)\n",
        "8. [Conclusion](#8-conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Project Overview\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "Researching the Crusades presents unique challenges:\n",
        "- **Language Barriers**: Primary sources exist in Latin, Arabic, Greek, Armenian, and Old French\n",
        "- **Scattered Archives**: Documents are distributed across multiple digital repositories\n",
        "- **Volume**: Thousands of pages must be manually searched to find relevant passages\n",
        "- **Perspective Bias**: Western sources dominate; Eastern perspectives are underrepresented\n",
        "\n",
        "### Solution\n",
        "\n",
        "Jerusalem RAG Explorer addresses these challenges through:\n",
        "- **Multilingual Corpus**: Aggregates Latin, Arabic, Greek, Armenian, and French sources\n",
        "- **AI Translation**: Pre-translates non-English texts during ingestion\n",
        "- **Semantic Search**: FAISS index enables natural language queries\n",
        "- **Grounded Answers**: LLM generates responses with mandatory source citations\n",
        "- **Comparative Analysis**: Compare Western, Eastern, and Byzantine perspectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. System Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                        DATA INGESTION                           â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  Archive.org  â”€â”€â”                                               â”‚\n",
        "â”‚  Gallica (BnF) â”€â”¼â”€â”€â–¶ Fetch â”€â”€â–¶ Chunk â”€â”€â–¶ Translate â”€â”€â–¶ Embed   â”‚\n",
        "â”‚  Wikipedia â”€â”€â”€â”€â”˜                                                â”‚\n",
        "â”‚                                            â”‚                    â”‚\n",
        "â”‚                                            â–¼                    â”‚\n",
        "â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\n",
        "â”‚                                    â”‚ FAISS Index  â”‚             â”‚\n",
        "â”‚                                    â”‚ + Metadata   â”‚             â”‚\n",
        "â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                        QUERY PIPELINE                           â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                 â”‚\n",
        "â”‚  User Question â”€â”€â–¶ Embed â”€â”€â–¶ FAISS Search â”€â”€â–¶ Top-K Chunks     â”‚\n",
        "â”‚                                                      â”‚          â”‚\n",
        "â”‚                                                      â–¼          â”‚\n",
        "â”‚                              Context + Prompt â”€â”€â–¶ Gemini LLM    â”‚\n",
        "â”‚                                                      â”‚          â”‚\n",
        "â”‚                                                      â–¼          â”‚\n",
        "â”‚                                          Answer with Citations  â”‚\n",
        "â”‚                                                                 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Technology Stack\n",
        "\n",
        "| Component | Technology | Purpose |\n",
        "|-----------|------------|---------|  \n",
        "| Frontend | Streamlit | Interactive web UI |\n",
        "| Embeddings | sentence-transformers | 384-dim text vectors |\n",
        "| Vector Search | FAISS | Fast similarity search |\n",
        "| LLM | Google Gemini | Answer generation |\n",
        "| Translation | Gemini API | Medieval text translation |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries loaded successfully!\n",
            "GEMINI_API_KEY: âœ“ Found\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(\"../.env\")\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "sys.path.insert(0, str(Path(\"..\").absolute()))\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n",
        "print(f\"GEMINI_API_KEY: {'âœ“ Found' if os.getenv('GEMINI_API_KEY') else 'âœ— Missing'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "INDEX_DIR = Path(\"../data/index_v2\")\n",
        "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "# Language utilities\n",
        "LANGUAGE_NAMES = {\"en\": \"English\", \"la\": \"Latin\", \"ar\": \"Arabic\", \"el\": \"Greek\", \"fr\": \"French\", \"hy\": \"Armenian\"}\n",
        "LANGUAGE_FLAGS = {\"en\": \"ğŸ‡¬ğŸ‡§\", \"la\": \"ğŸ‡»ğŸ‡¦\", \"ar\": \"ğŸ‡¸ğŸ‡¦\", \"el\": \"ğŸ‡¬ğŸ‡·\", \"fr\": \"ğŸ‡«ğŸ‡·\", \"hy\": \"ğŸ‡¦ğŸ‡²\"}\n",
        "\n",
        "def get_lang_name(code): return LANGUAGE_NAMES.get(code, code.upper())\n",
        "def get_lang_flag(code): return LANGUAGE_FLAGS.get(code, \"ğŸŒ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Pipeline Demo\n",
        "\n",
        "### 4.1 Document Sources\n",
        "\n",
        "The system fetches documents from:\n",
        "- **Archive.org**: Recueil des historiens des croisades (Latin, Arabic, Greek, Armenian)\n",
        "- **Wikipedia**: Modern encyclopedic content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in corpus: 76\n",
            "\n",
            "Sample documents:\n",
            "  - 39020004691971-godeffroyofbolo.txt\n",
            "  - godeffroyboloyn00tyregoog.txt\n",
            "  - godeffroyofboloy00willrich.txt\n",
            "  - guillaumedetyre01willgoog.txt\n",
            "  - HistoryAndLiteratureOfCrusades.txt\n"
          ]
        }
      ],
      "source": [
        "# Show sample source documents\n",
        "data_dir = Path(\"../data/raw\")\n",
        "\n",
        "if data_dir.exists():\n",
        "    txt_files = list(data_dir.rglob(\"*.txt\"))\n",
        "    print(f\"Total documents in corpus: {len(txt_files)}\")\n",
        "    print(\"\\nSample documents:\")\n",
        "    for f in txt_files[:5]:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(\"Data directory not found. Run 01_data_fetching.ipynb first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Chunking Strategy\n",
        "\n",
        "Documents are split into overlapping segments:\n",
        "- **Chunk size**: 2000 characters\n",
        "- **Overlap**: 300 characters (preserves context across boundaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Demo: 5000 chars â†’ 3 chunks\n",
            "Chunk sizes: [2000, 2000, 1600]\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text, chunk_size=2000, overlap=300):\n",
        "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        chunks.append(text[i:i + chunk_size].strip())\n",
        "        i += chunk_size - overlap\n",
        "    return [c for c in chunks if c]\n",
        "\n",
        "# Demonstrate\n",
        "demo_text = \"A\" * 5000\n",
        "demo_chunks = chunk_text(demo_text)\n",
        "print(f\"Demo: {len(demo_text)} chars â†’ {len(demo_chunks)} chunks\")\n",
        "print(f\"Chunk sizes: {[len(c) for c in demo_chunks]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Load Processed Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
            "Loading FAISS index...\n",
            "  Index contains 41983 vectors\n",
            "Loading chunks metadata...\n",
            "  Loaded 41983 chunks\n",
            "\n",
            "Chunks by language:\n",
            "  ğŸ‡«ğŸ‡· French: 11145\n",
            "  ğŸ‡¬ğŸ‡§ English: 10745\n",
            "  ğŸ‡»ğŸ‡¦ Latin: 9605\n",
            "  ğŸ‡¸ğŸ‡¦ Arabic: 6454\n",
            "  ğŸ‡¬ğŸ‡· Greek: 4034\n"
          ]
        }
      ],
      "source": [
        "# Load embedding model\n",
        "print(f\"Loading embedding model: {MODEL_NAME}\")\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "# Load FAISS index\n",
        "print(f\"Loading FAISS index...\")\n",
        "index = faiss.read_index(str(INDEX_DIR / \"faiss.index\"))\n",
        "print(f\"  Index contains {index.ntotal} vectors\")\n",
        "\n",
        "# Load chunks\n",
        "print(f\"Loading chunks metadata...\")\n",
        "with open(INDEX_DIR / \"chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    chunks = json.load(f)\n",
        "print(f\"  Loaded {len(chunks)} chunks\")\n",
        "\n",
        "# Count by language\n",
        "lang_counts = {}\n",
        "for c in chunks:\n",
        "    lang = c.get(\"language\", \"en\")\n",
        "    lang_counts[lang] = lang_counts.get(lang, 0) + 1\n",
        "\n",
        "print(\"\\nChunks by language:\")\n",
        "for lang, count in sorted(lang_counts.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  {get_lang_flag(lang)} {get_lang_name(lang)}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Retrieval Demo\n",
        "\n",
        "The retrieval system:\n",
        "1. Embeds the query using the same model\n",
        "2. Searches the FAISS index for similar vectors\n",
        "3. Returns top-k chunks with relevance scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve(question, top_k=6, languages=None):\n",
        "    \"\"\"Retrieve top-k relevant chunks.\"\"\"\n",
        "    # Embed query\n",
        "    q_emb = model.encode([question], normalize_embeddings=True)\n",
        "    q_emb = np.array(q_emb, dtype=\"float32\")\n",
        "    \n",
        "    # Search\n",
        "    search_k = top_k * 3 if languages else top_k\n",
        "    scores, ids = index.search(q_emb, search_k)\n",
        "    \n",
        "    results = []\n",
        "    for score, idx in zip(scores[0], ids[0]):\n",
        "        if idx < 0 or idx >= len(chunks):\n",
        "            continue\n",
        "        chunk = chunks[idx]\n",
        "        \n",
        "        # Language filter\n",
        "        if languages:\n",
        "            if chunk.get(\"language\", \"en\") not in languages:\n",
        "                continue\n",
        "        \n",
        "        results.append((float(score), chunk))\n",
        "        if len(results) >= top_k:\n",
        "            break\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'What happened at the Battle of Hattin?'\n",
            "\n",
            "Retrieved 5 chunks:\n",
            "\n",
            "1. [Battle_of_Hattin_chunk_000] Score: 0.706 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: TITLE: Battle of Hattin\n",
            "\n",
            "The Battle of Hattin took place on 4 July 1187, between the Crusader states of the Levant and the forces of the Ayyubid sulta...\n",
            "\n",
            "2. [Crusader_states_chunk_027] Score: 0.594 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: lated the truce and prompted Saladin to assemble his forces for the jihÄd. Raymond allowed Muslim troops to pass through Galilee to raid around Acre. ...\n",
            "\n",
            "3. [william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_501] Score: 0.539 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: here fighting at close quarters became necessary. The kingâ€™s division \n",
            "advanced valiantly as with one thought; they overwhelmed Shirkuhâ€™s \n",
            "cohorts and...\n",
            "\n",
            "4. [william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_492] Score: 0.539 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: ng learned that the enemy had seized the island, \n",
            "he sent thither Milon de Plancy and Chemel [Kamil], a son of the \n",
            "sultan, with a force of knights. T...\n",
            "\n",
            "5. [williamoftyrehistory_chunk_1615] Score: 0.538 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: he  besieged  no  rest  and  had  done  them  great  inÂ¬ \n",
            "jury.  Those  in  the  fortress  had  been  showered  with  arrows  so  conÂ¬ \n",
            "tinually  that...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Demo retrieval\n",
        "question = \"What happened at the Battle of Hattin?\"\n",
        "results = retrieve(question, top_k=5)\n",
        "\n",
        "print(f\"Query: '{question}'\\n\")\n",
        "print(f\"Retrieved {len(results)} chunks:\\n\")\n",
        "\n",
        "for i, (score, chunk) in enumerate(results):\n",
        "    lang = chunk.get(\"language\", \"en\")\n",
        "    flag = get_lang_flag(lang)\n",
        "    is_trans = \"(translated)\" if chunk.get(\"is_translation\") else \"\"\n",
        "    \n",
        "    print(f\"{i+1}. [{chunk['chunk_id']}] Score: {score:.3f} {flag} {is_trans}\")\n",
        "    print(f\"   Preview: {chunk['text'][:150]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Question Answering Demo\n",
        "\n",
        "The complete RAG pipeline:\n",
        "1. **Retrieve** relevant chunks\n",
        "2. **Format** context with metadata\n",
        "3. **Generate** answer with Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a scholarly historian specializing in the Crusades (1095-1291 CE).\n",
        "\n",
        "RULES:\n",
        "1. Answer ONLY using the provided CONTEXT\n",
        "2. EVERY claim must cite [ChunkID]\n",
        "3. Note original language of translated sources\n",
        "4. If insufficient information, say so\n",
        "\"\"\"\n",
        "\n",
        "def format_context(results):\n",
        "    \"\"\"Format chunks for LLM.\"\"\"\n",
        "    parts = []\n",
        "    for score, chunk in results:\n",
        "        header = f\"[{chunk['chunk_id']}] (score: {score:.3f})\"\n",
        "        if chunk.get(\"original_language\"):\n",
        "            header += f\" [Translated from {get_lang_name(chunk['original_language'])}]\"\n",
        "        parts.append(f\"{header}\\n{chunk['text']}\")\n",
        "    return \"\\n\\n---\\n\\n\".join(parts)\n",
        "\n",
        "def ask_question(question, mode=\"default\", top_k=6):\n",
        "    \"\"\"Complete RAG pipeline.\"\"\"\n",
        "    # Retrieve\n",
        "    results = retrieve(question, top_k=top_k)\n",
        "    if not results:\n",
        "        return \"No relevant sources found.\", []\n",
        "    \n",
        "    # Format context\n",
        "    context = format_context(results)\n",
        "    \n",
        "    # Build prompt\n",
        "    prompt = f\"{SYSTEM_PROMPT}\\n\\nQUESTION: {question}\\n\\nCONTEXT:\\n{context}\\n\\nANSWER:\"\n",
        "    \n",
        "    # Generate\n",
        "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "    config = types.GenerateContentConfig(temperature=0.3, max_output_tokens=4096)\n",
        "    resp = client.models.generate_content(\n",
        "        model=\"gemini-3-flash-preview\",\n",
        "        contents=prompt,\n",
        "        config=config\n",
        "    )\n",
        "    \n",
        "    return resp.text or \"\", results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What happened at the Battle of Hattin?\n",
            "============================================================\n",
            "\n",
            "ANSWER:\n",
            "The Battle of Hattin, also known as the Battle of the Horns of Hattin due to the nearby extinct volcano, took place on 4 July 1187 [Battle_of_Hattin_chunk_000]. It was a decisive confrontation between the Crusader states of the Levant and the Ayyubid sultan Saladin [Battle_of_Hattin_chunk_000].\n",
            "\n",
            "### Prelude and Context\n",
            "The conflict was preceded by internal divisions within the Kingdom of Jerusalem between the \"court faction\" (led by King Guy of Lusignan and Raynald of ChÃ¢tillon) and the \"nobles' faction\" (led by Raymond III of Tripoli) [Battle_of_Hattin_chunk_000]. According to the Muslim chronicler Ali ibn al-Athir (originally writing in Arabic), Raymond had initially opposed Guy's succession [Battle_of_Hattin_chunk_000]. \n",
            "\n",
            "The immediate provocation for the battle was Raynald of ChÃ¢tillonâ€™s violation of a truce, which prompted Saladin to assemble his forces for *jihÄd* [Crusader_states_chunk_027]. When Saladin besieged Raymondâ€™s castle at Tiberias, the Crusader leadership divided on tactics: Raymond advised defensive caution, while Raynald urged an offensive [Crusader_states_chunk_027]. King Guy ultimately chose to march toward Tiberias [Crusader_states_chunk_027].\n",
            "\n",
            "### The Engagement\n",
            "The battle occurred near the village of Hittin, close to a pass through the northern mountains between Tiberias and Acre [Battle_of_Hattin_chunk_000]. The Frankish army underwent an \"arduous\" march and was \"exhausted\" by the time they reached the Horns of Hattin [Crusader_states_chunk_027]. Saladinâ€™s forces overwhelmed the Crusader army, capturing or killing the vast majority of their troops [Battle_of_Hattin_chunk_000]. \n",
            "\n",
            "### Outcome and Casualties\n",
            "The defeat was catastrophic for the Crusaders:\n",
            "*   **Captives and Executions:** Nearly all major Frankish leaders were taken prisoner [Crusader_states_chunk_027]. While most were held, Saladin personally executed Raynald of ChÃ¢tillon and ordered the execution of the armed monks from the military orders [Crusader_states_chunk_027].\n",
            "*   **Escapes:** Raymond III of Tripoli was one of the few leaders to escape captivity, though only approximately 200 knights in total survived the battle [Crusader_states_chunk_027, Battle_of_Hattin_chunk_009].\n",
            "*   **Loss of Territory:** The battle removed the Crusaders' capability to wage war [Battle_of_Hattin_chunk_000]. In its aftermath, Saladin captured 52 towns and fortifications, including Acre, Sidon, and Beirut [Battle_of_Hattin_chunk_009]. Jerusalem surrendered to Saladin on 2 October 1187 [Crusader_states_chunk_027].\n",
            "\n",
            "### Historical Significance\n",
            "The battle re-established Muslims as the eminent military power in the Holy Land [Battle_of_Hattin_chunk_000]. According to the chronicler Ernoul (originally writing in Old French), news of the defeat caused Pope Urban III to die of shock [Battle_of_Hattin_chunk_009]. His successor, Pope Gregory VIII, issued the bull *Audita tremendi* to call for the Third Crusade [Battle_of_Hattin_chunk_009, Crusader_states_chunk_027]. Crusader military power in Outremer would not fully collapse until the Battle of La Forbie in 1244 [Battle_of_Hattin_chunk_009].\n",
            "\n",
            "============================================================\n",
            "SOURCES:\n",
            "  ğŸ‡¬ğŸ‡§ Battle_of_Hattin_chunk_000 (score: 0.706)\n",
            "  ğŸ‡¬ğŸ‡§ Crusader_states_chunk_027 (score: 0.594)\n",
            "  ğŸ‡¬ğŸ‡§ william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_501 (score: 0.539)\n",
            "  ğŸ‡¬ğŸ‡§ william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_492 (score: 0.539)\n",
            "  ğŸ‡¬ğŸ‡§ williamoftyrehistory_chunk_1615 (score: 0.538)\n",
            "  ğŸ‡¬ğŸ‡§ Battle_of_Hattin_chunk_009 (score: 0.537)\n"
          ]
        }
      ],
      "source": [
        "# Demo question answering\n",
        "question = \"What happened at the Battle of Hattin?\"\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "answer, sources = ask_question(question, top_k=6)\n",
        "\n",
        "print(\"\\nANSWER:\")\n",
        "print(answer)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SOURCES:\")\n",
        "for score, chunk in sources:\n",
        "    flag = get_lang_flag(chunk.get(\"language\", \"en\"))\n",
        "    print(f\"  {flag} {chunk['chunk_id']} (score: {score:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Response Modes\n",
        "\n",
        "The system supports multiple response formats:\n",
        "\n",
        "| Mode | Description |\n",
        "|------|-------------|\n",
        "| **default** | Scholarly prose with citations |\n",
        "| **chronology** | Timeline format |\n",
        "| **dossier** | Structured report |\n",
        "| **comparative** | Cross-cultural analysis |\n",
        "| **claim_check** | Fact verification |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Q: Who was Baldwin IV of Jerusalem?\n",
            "============================================================\n",
            "\n",
            "A: Based on the provided historical records, Baldwin IV of Jerusalem was the king of Jerusalem who reigned from 1174 until his death in 1185 [Baldwin_IV__disambiguation__chunk_000], [williamoftyrehistory_chunk_1468].\n",
            "\n",
            "Key details regarding his life and reign include:\n",
            "\n",
            "*   **Lineage and Birth:** Baldwin IV was the son of King Amaury (Amalric) [williamoftyrehistory_chunk_1468]. He was born in 1161, a date inferred from contemporary accounts stating he was nine years old in 1170 and thirteen at the ti...\n",
            "\n",
            "[4 sources used]\n",
            "\n",
            "============================================================\n",
            "Q: What were the laws of the Kingdom of Jerusalem?\n",
            "============================================================\n",
            "\n",
            "A: Based on the provided historical context, the laws of the Kingdom of Jerusalem are characterized by the following:\n",
            "\n",
            "### The Assizes of Jerusalem\n",
            "The primary body of law for the kingdom is known as the **Assizes of Jerusalem**, a collection of medieval legal treatises written in **Old French** [Assizes_of_Jerusalem_chunk_000]. These treatises were compiled in the 13th century and represent the largest surviving collection of medieval laws, though they also contain laws for the Kingdom of Cyprus [...\n",
            "\n",
            "[4 sources used]\n",
            "\n",
            "============================================================\n",
            "Q: How did Arabic sources describe the Crusaders?\n",
            "============================================================\n",
            "\n",
            "A: Based on the provided context, there is **insufficient information** to provide specific details on how Arabic sources characterized or described the Crusaders (such as specific adjectives, narratives, or cultural impressions). The provided text primarily lists the titles of primary sources and the names of historians rather than the content of their descriptions.\n",
            "\n",
            "However, the context identifies several key primary sources, originally written in **Arabic**, that document the Crusader period fro...\n",
            "\n",
            "[4 sources used]\n"
          ]
        }
      ],
      "source": [
        "# Try different questions\n",
        "questions = [\n",
        "    \"Who was Baldwin IV of Jerusalem?\",\n",
        "    \"What were the laws of the Kingdom of Jerusalem?\",\n",
        "    \"How did Arabic sources describe the Crusaders?\",\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Q: {q}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    answer, sources = ask_question(q, top_k=4)\n",
        "    print(f\"\\nA: {answer[:500]}...\" if len(answer) > 500 else f\"\\nA: {answer}\")\n",
        "    print(f\"\\n[{len(sources)} sources used]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "### Summary\n",
        "\n",
        "Jerusalem RAG Explorer demonstrates how RAG systems can:\n",
        "- **Bridge language barriers** through AI translation\n",
        "- **Enable semantic search** across historical documents\n",
        "- **Maintain scholarly rigor** through mandatory citations\n",
        "- **Reveal multiple perspectives** on historical events\n",
        "\n",
        "### Key Achievements\n",
        "\n",
        "1. **Multilingual Corpus**: Latin, Arabic, Greek, Armenian, French sources\n",
        "2. **Pre-translation Pipeline**: Non-English texts translated during ingestion\n",
        "3. **Semantic Retrieval**: FAISS index with 384-dim embeddings\n",
        "4. **Grounded Generation**: Every answer cites specific sources\n",
        "5. **Comparative Analysis**: Compare Eastern vs Western perspectives\n",
        "\n",
        "### Future Work\n",
        "\n",
        "- Fine-tune embeddings on medieval historical text\n",
        "- Add more sources (Vatican Library, British Library)\n",
        "- Implement hybrid search (BM25 + semantic)\n",
        "- Add citation verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**By Yotam Nachtomy-Katz** | ID: 211718366 | Haifa University | Information Retrieval Course | 01.02.26"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
