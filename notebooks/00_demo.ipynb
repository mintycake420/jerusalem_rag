{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jerusalem RAG Explorer - Complete Demo\n",
        "\n",
        "## A Retrieval-Augmented Generation System for Crusader History Research\n",
        "\n",
        "**By Yotam Nachtomy-Katz**  \n",
        "**ID: 211718366**  \n",
        "**Submitted: 01.02.26**  \n",
        "**Course: Information Retrieval**  \n",
        "**Haifa University**\n",
        "\n",
        "---\n",
        "\n",
        "This notebook provides a complete demonstration of the Jerusalem RAG Explorer system, from data ingestion to question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Project Overview](#1-project-overview)\n",
        "2. [System Architecture](#2-system-architecture)\n",
        "3. [Setup](#3-setup)\n",
        "4. [Data Pipeline Demo](#4-data-pipeline-demo)\n",
        "5. [Retrieval Demo](#5-retrieval-demo)\n",
        "6. [Question Answering Demo](#6-question-answering-demo)\n",
        "7. [Response Modes](#7-response-modes)\n",
        "8. [Conclusion](#8-conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Project Overview\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "Researching the Crusades presents unique challenges:\n",
        "- **Language Barriers**: Primary sources exist in Latin, Arabic, Greek, Armenian, and Old French\n",
        "- **Scattered Archives**: Documents are distributed across multiple digital repositories\n",
        "- **Volume**: Thousands of pages must be manually searched to find relevant passages\n",
        "- **Perspective Bias**: Western sources dominate; Eastern perspectives are underrepresented\n",
        "\n",
        "### Solution\n",
        "\n",
        "Jerusalem RAG Explorer addresses these challenges through:\n",
        "- **Multilingual Corpus**: Aggregates Latin, Arabic, Greek, Armenian, and French sources\n",
        "- **AI Translation**: Pre-translates non-English texts during ingestion\n",
        "- **Semantic Search**: FAISS index enables natural language queries\n",
        "- **Grounded Answers**: LLM generates responses with mandatory source citations\n",
        "- **Comparative Analysis**: Compare Western, Eastern, and Byzantine perspectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. System Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                        DATA INGESTION                           â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  Archive.org  â”€â”€â”                                               â”‚\n",
        "â”‚  Gallica (BnF) â”€â”¼â”€â”€â–¶ Fetch â”€â”€â–¶ Chunk â”€â”€â–¶ Translate â”€â”€â–¶ Embed   â”‚\n",
        "â”‚  Wikipedia â”€â”€â”€â”€â”˜                                                â”‚\n",
        "â”‚                                            â”‚                    â”‚\n",
        "â”‚                                            â–¼                    â”‚\n",
        "â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚\n",
        "â”‚                                    â”‚ FAISS Index  â”‚             â”‚\n",
        "â”‚                                    â”‚ + Metadata   â”‚             â”‚\n",
        "â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                        QUERY PIPELINE                           â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                 â”‚\n",
        "â”‚  User Question â”€â”€â–¶ Embed â”€â”€â–¶ FAISS Search â”€â”€â–¶ Top-K Chunks     â”‚\n",
        "â”‚                                                      â”‚          â”‚\n",
        "â”‚                                                      â–¼          â”‚\n",
        "â”‚                              Context + Prompt â”€â”€â–¶ Gemini LLM    â”‚\n",
        "â”‚                                                      â”‚          â”‚\n",
        "â”‚                                                      â–¼          â”‚\n",
        "â”‚                                          Answer with Citations  â”‚\n",
        "â”‚                                                                 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "### Technology Stack\n",
        "\n",
        "| Component | Technology | Purpose |\n",
        "|-----------|------------|---------|  \n",
        "| Frontend | Streamlit | Interactive web UI |\n",
        "| Embeddings | sentence-transformers | 384-dim text vectors |\n",
        "| Vector Search | FAISS | Fast similarity search |\n",
        "| LLM | Google Gemini | Answer generation |\n",
        "| Translation | Gemini API | Medieval text translation |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries loaded successfully!\n",
            "GEMINI_API_KEY: âœ“ Found\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(\"../.env\")\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "sys.path.insert(0, str(Path(\"..\").absolute()))\n",
        "\n",
        "print(\"Libraries loaded successfully!\")\n",
        "print(f\"GEMINI_API_KEY: {'âœ“ Found' if os.getenv('GEMINI_API_KEY') else 'âœ— Missing'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "INDEX_DIR = Path(\"../data/index_v2\")\n",
        "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "# Language utilities\n",
        "LANGUAGE_NAMES = {\"en\": \"English\", \"la\": \"Latin\", \"ar\": \"Arabic\", \"el\": \"Greek\", \"fr\": \"French\", \"hy\": \"Armenian\"}\n",
        "LANGUAGE_FLAGS = {\"en\": \"ğŸ‡¬ğŸ‡§\", \"la\": \"ğŸ‡»ğŸ‡¦\", \"ar\": \"ğŸ‡¸ğŸ‡¦\", \"el\": \"ğŸ‡¬ğŸ‡·\", \"fr\": \"ğŸ‡«ğŸ‡·\", \"hy\": \"ğŸ‡¦ğŸ‡²\"}\n",
        "\n",
        "def get_lang_name(code): return LANGUAGE_NAMES.get(code, code.upper())\n",
        "def get_lang_flag(code): return LANGUAGE_FLAGS.get(code, \"ğŸŒ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Pipeline Demo\n",
        "\n",
        "### 4.1 Document Sources\n",
        "\n",
        "The system fetches documents from:\n",
        "- **Archive.org**: Recueil des historiens des croisades (Latin, Arabic, Greek, Armenian)\n",
        "- **Gallica (BnF)**: French National Library manuscripts\n",
        "- **Wikipedia**: Modern encyclopedic content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents in corpus: 76\n",
            "\n",
            "Sample documents:\n",
            "  - 39020004691971-godeffroyofbolo.txt\n",
            "  - godeffroyboloyn00tyregoog.txt\n",
            "  - godeffroyofboloy00willrich.txt\n",
            "  - guillaumedetyre01willgoog.txt\n",
            "  - HistoryAndLiteratureOfCrusades.txt\n"
          ]
        }
      ],
      "source": [
        "# Show sample source documents\n",
        "data_dir = Path(\"../data/raw\")\n",
        "\n",
        "if data_dir.exists():\n",
        "    txt_files = list(data_dir.rglob(\"*.txt\"))\n",
        "    print(f\"Total documents in corpus: {len(txt_files)}\")\n",
        "    print(\"\\nSample documents:\")\n",
        "    for f in txt_files[:5]:\n",
        "        print(f\"  - {f.name}\")\n",
        "else:\n",
        "    print(\"Data directory not found. Run 01_data_fetching.ipynb first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Chunking Strategy\n",
        "\n",
        "Documents are split into overlapping segments:\n",
        "- **Chunk size**: 2000 characters\n",
        "- **Overlap**: 300 characters (preserves context across boundaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Demo: 5000 chars â†’ 3 chunks\n",
            "Chunk sizes: [2000, 2000, 1600]\n"
          ]
        }
      ],
      "source": [
        "def chunk_text(text, chunk_size=2000, overlap=300):\n",
        "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        chunks.append(text[i:i + chunk_size].strip())\n",
        "        i += chunk_size - overlap\n",
        "    return [c for c in chunks if c]\n",
        "\n",
        "# Demonstrate\n",
        "demo_text = \"A\" * 5000\n",
        "demo_chunks = chunk_text(demo_text)\n",
        "print(f\"Demo: {len(demo_text)} chars â†’ {len(demo_chunks)} chunks\")\n",
        "print(f\"Chunk sizes: {[len(c) for c in demo_chunks]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Load Processed Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
            "Loading FAISS index...\n",
            "  Index contains 41983 vectors\n",
            "Loading chunks metadata...\n",
            "  Loaded 41983 chunks\n",
            "\n",
            "Chunks by language:\n",
            "  ğŸ‡«ğŸ‡· French: 11145\n",
            "  ğŸ‡¬ğŸ‡§ English: 10745\n",
            "  ğŸ‡»ğŸ‡¦ Latin: 9605\n",
            "  ğŸ‡¸ğŸ‡¦ Arabic: 6454\n",
            "  ğŸ‡¬ğŸ‡· Greek: 4034\n"
          ]
        }
      ],
      "source": [
        "# Load embedding model\n",
        "print(f\"Loading embedding model: {MODEL_NAME}\")\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "# Load FAISS index\n",
        "print(f\"Loading FAISS index...\")\n",
        "index = faiss.read_index(str(INDEX_DIR / \"faiss.index\"))\n",
        "print(f\"  Index contains {index.ntotal} vectors\")\n",
        "\n",
        "# Load chunks\n",
        "print(f\"Loading chunks metadata...\")\n",
        "with open(INDEX_DIR / \"chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    chunks = json.load(f)\n",
        "print(f\"  Loaded {len(chunks)} chunks\")\n",
        "\n",
        "# Count by language\n",
        "lang_counts = {}\n",
        "for c in chunks:\n",
        "    lang = c.get(\"language\", \"en\")\n",
        "    lang_counts[lang] = lang_counts.get(lang, 0) + 1\n",
        "\n",
        "print(\"\\nChunks by language:\")\n",
        "for lang, count in sorted(lang_counts.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  {get_lang_flag(lang)} {get_lang_name(lang)}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Retrieval Demo\n",
        "\n",
        "The retrieval system:\n",
        "1. Embeds the query using the same model\n",
        "2. Searches the FAISS index for similar vectors\n",
        "3. Returns top-k chunks with relevance scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve(question, top_k=6, languages=None):\n",
        "    \"\"\"Retrieve top-k relevant chunks.\"\"\"\n",
        "    # Embed query\n",
        "    q_emb = model.encode([question], normalize_embeddings=True)\n",
        "    q_emb = np.array(q_emb, dtype=\"float32\")\n",
        "    \n",
        "    # Search\n",
        "    search_k = top_k * 3 if languages else top_k\n",
        "    scores, ids = index.search(q_emb, search_k)\n",
        "    \n",
        "    results = []\n",
        "    for score, idx in zip(scores[0], ids[0]):\n",
        "        if idx < 0 or idx >= len(chunks):\n",
        "            continue\n",
        "        chunk = chunks[idx]\n",
        "        \n",
        "        # Language filter\n",
        "        if languages:\n",
        "            if chunk.get(\"language\", \"en\") not in languages:\n",
        "                continue\n",
        "        \n",
        "        results.append((float(score), chunk))\n",
        "        if len(results) >= top_k:\n",
        "            break\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 'What happened at the Battle of Hattin?'\n",
            "\n",
            "Retrieved 5 chunks:\n",
            "\n",
            "1. [Battle_of_Hattin_chunk_000] Score: 0.706 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: TITLE: Battle of Hattin\n",
            "\n",
            "The Battle of Hattin took place on 4 July 1187, between the Crusader states of the Levant and the forces of the Ayyubid sulta...\n",
            "\n",
            "2. [Crusader_states_chunk_027] Score: 0.594 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: lated the truce and prompted Saladin to assemble his forces for the jihÄd. Raymond allowed Muslim troops to pass through Galilee to raid around Acre. ...\n",
            "\n",
            "3. [william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_501] Score: 0.539 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: here fighting at close quarters became necessary. The kingâ€™s division \n",
            "advanced valiantly as with one thought; they overwhelmed Shirkuhâ€™s \n",
            "cohorts and...\n",
            "\n",
            "4. [william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_492] Score: 0.539 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: ng learned that the enemy had seized the island, \n",
            "he sent thither Milon de Plancy and Chemel [Kamil], a son of the \n",
            "sultan, with a force of knights. T...\n",
            "\n",
            "5. [williamoftyrehistory_chunk_1615] Score: 0.538 ğŸ‡¬ğŸ‡§ \n",
            "   Preview: he  besieged  no  rest  and  had  done  them  great  inÂ¬ \n",
            "jury.  Those  in  the  fortress  had  been  showered  with  arrows  so  conÂ¬ \n",
            "tinually  that...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Demo retrieval\n",
        "question = \"What happened at the Battle of Hattin?\"\n",
        "results = retrieve(question, top_k=5)\n",
        "\n",
        "print(f\"Query: '{question}'\\n\")\n",
        "print(f\"Retrieved {len(results)} chunks:\\n\")\n",
        "\n",
        "for i, (score, chunk) in enumerate(results):\n",
        "    lang = chunk.get(\"language\", \"en\")\n",
        "    flag = get_lang_flag(lang)\n",
        "    is_trans = \"(translated)\" if chunk.get(\"is_translation\") else \"\"\n",
        "    \n",
        "    print(f\"{i+1}. [{chunk['chunk_id']}] Score: {score:.3f} {flag} {is_trans}\")\n",
        "    print(f\"   Preview: {chunk['text'][:150]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Question Answering Demo\n",
        "\n",
        "The complete RAG pipeline:\n",
        "1. **Retrieve** relevant chunks\n",
        "2. **Format** context with metadata\n",
        "3. **Generate** answer with Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a scholarly historian specializing in the Crusades (1095-1291 CE).\n",
        "\n",
        "RULES:\n",
        "1. Answer ONLY using the provided CONTEXT\n",
        "2. EVERY claim must cite [ChunkID]\n",
        "3. Note original language of translated sources\n",
        "4. If insufficient information, say so\n",
        "\"\"\"\n",
        "\n",
        "def format_context(results):\n",
        "    \"\"\"Format chunks for LLM.\"\"\"\n",
        "    parts = []\n",
        "    for score, chunk in results:\n",
        "        header = f\"[{chunk['chunk_id']}] (score: {score:.3f})\"\n",
        "        if chunk.get(\"original_language\"):\n",
        "            header += f\" [Translated from {get_lang_name(chunk['original_language'])}]\"\n",
        "        parts.append(f\"{header}\\n{chunk['text']}\")\n",
        "    return \"\\n\\n---\\n\\n\".join(parts)\n",
        "\n",
        "def ask_question(question, mode=\"default\", top_k=6):\n",
        "    \"\"\"Complete RAG pipeline.\"\"\"\n",
        "    # Retrieve\n",
        "    results = retrieve(question, top_k=top_k)\n",
        "    if not results:\n",
        "        return \"No relevant sources found.\", []\n",
        "    \n",
        "    # Format context\n",
        "    context = format_context(results)\n",
        "    \n",
        "    # Build prompt\n",
        "    prompt = f\"{SYSTEM_PROMPT}\\n\\nQUESTION: {question}\\n\\nCONTEXT:\\n{context}\\n\\nANSWER:\"\n",
        "    \n",
        "    # Generate\n",
        "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "    config = types.GenerateContentConfig(temperature=0.3, max_output_tokens=4096)\n",
        "    resp = client.models.generate_content(\n",
        "        model=\"gemini-3-flash-preview\",\n",
        "        contents=prompt,\n",
        "        config=config\n",
        "    )\n",
        "    \n",
        "    return resp.text or \"\", results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What happened at the Battle of Hattin?\n",
            "============================================================\n",
            "\n",
            "ANSWER:\n",
            "The Battle of Hattin, fought on 4 July 1187, was a pivotal engagement between the Crusader states of the Levant and the Ayyubid forces under Sultan Saladin [Battle_of_Hattin_chunk_000].\n",
            "\n",
            "### Location and Context\n",
            "The battle occurred near Tiberias in present-day Israel, centered around a double hill known as the \"Horns of Hattin,\" an extinct volcano [Battle_of_Hattin_chunk_000]. The conflict arose amid internal divisions in the Kingdom of Jerusalem between the \"court faction\" (King Guy of Lusignan, Raynald of ChÃ¢tillon, and the Templars) and the \"nobles' faction\" (Raymond III of Tripoli) [Battle_of_Hattin_chunk_000]. \n",
            "\n",
            "### The Engagement\n",
            "Following a Muslim raid near Acre and Saladinâ€™s siege of Raymond IIIâ€™s castle at Tiberias, King Guy gathered the kingdom's full resources [Crusader_states_chunk_027]. Despite Raymondâ€™s advice to maintain a defensive posture, Guy ordered a march to relieve Tiberias [Crusader_states_chunk_027]. The march was described as \"arduous,\" and the Frankish army arrived at the Horns of Hattin exhausted [Crusader_states_chunk_027]. Saladinâ€™s forces overwhelmed the Crusaders, capturing or killing the vast majority of their troops [Battle_of_Hattin_chunk_000].\n",
            "\n",
            "### Immediate Outcomes\n",
            "*   **Casualties and Captives:** Nearly all major Frankish leaders were taken prisoner [Crusader_states_chunk_027]. While most were held, Saladin personally executed Raynald of ChÃ¢tillon and ordered the execution of the armed monks from the military orders [Crusader_states_chunk_027]. \n",
            "*   **Survivors:** Only about 200 knights escaped the battle, including Raymond III of Tripoli [Crusader_states_chunk_027, Battle_of_Hattin_chunk_009].\n",
            "*   **Territorial Loss:** The defeat removed the Crusaders' capability to wage war [Battle_of_Hattin_chunk_000]. In the aftermath, Saladin captured 52 towns and fortifications, including Acre, Sidon, Beirut, and Ascalon [Battle_of_Hattin_chunk_009]. \n",
            "*   **Fall of Jerusalem:** The city of Jerusalem, defended by Queen Sibylla and Balian of Ibelin, surrendered to Saladin on 2 October 1187 [Crusader_states_chunk_027, Battle_of_Hattin_chunk_009].\n",
            "\n",
            "### Historical Significance\n",
            "The battle re-established Muslims as the eminent military power in the Holy Land [Battle_of_Hattin_chunk_000]. According to the chronicler Ernoul, news of the defeat allegedly caused Pope Urban III to die of shock [Battle_of_Hattin_chunk_009]. His successor, Pope Gregory VIII, called for the Third Crusade to reclaim lost territories [Crusader_states_chunk_027, Battle_of_Hattin_chunk_009].\n",
            "\n",
            "***\n",
            "\n",
            "**Note on Sources:** The provided text references accounts from the Muslim chronicler Ali ibn al-Athir (originally in Arabic) and the Frankish chronicler Ernoul (originally in Old French) [Battle_of_Hattin_chunk_000, Battle_of_Hattin_chunk_009]. Other provided excerpts regarding King Amaury I and Shirkuh describe earlier 12th-century conflicts and do not pertain to the 1187 Battle of Hattin [william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_501, william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_492].\n",
            "\n",
            "============================================================\n",
            "SOURCES:\n",
            "  ğŸ‡¬ğŸ‡§ Battle_of_Hattin_chunk_000 (score: 0.706)\n",
            "  ğŸ‡¬ğŸ‡§ Crusader_states_chunk_027 (score: 0.594)\n",
            "  ğŸ‡¬ğŸ‡§ william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_501 (score: 0.539)\n",
            "  ğŸ‡¬ğŸ‡§ william-of-tyre-deeds-done-beyond-the-sea-volume-ii_chunk_492 (score: 0.539)\n",
            "  ğŸ‡¬ğŸ‡§ williamoftyrehistory_chunk_1615 (score: 0.538)\n",
            "  ğŸ‡¬ğŸ‡§ Battle_of_Hattin_chunk_009 (score: 0.537)\n"
          ]
        }
      ],
      "source": [
        "# Demo question answering\n",
        "question = \"What happened at the Battle of Hattin?\"\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "answer, sources = ask_question(question, top_k=6)\n",
        "\n",
        "print(\"\\nANSWER:\")\n",
        "print(answer)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SOURCES:\")\n",
        "for score, chunk in sources:\n",
        "    flag = get_lang_flag(chunk.get(\"language\", \"en\"))\n",
        "    print(f\"  {flag} {chunk['chunk_id']} (score: {score:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Response Modes\n",
        "\n",
        "The system supports multiple response formats:\n",
        "\n",
        "| Mode | Description |\n",
        "|------|-------------|\n",
        "| **default** | Scholarly prose with citations |\n",
        "| **chronology** | Timeline format |\n",
        "| **dossier** | Structured report |\n",
        "| **comparative** | Cross-cultural analysis |\n",
        "| **claim_check** | Fact verification |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Q: Who was Baldwin IV of Jerusalem?\n",
            "============================================================\n"
          ]
        },
        {
          "ename": "ClientError",
          "evalue": "403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m answer, sources = \u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer[:\u001b[32m500\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(answer) > \u001b[32m500\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sources)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m sources used]\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mask_question\u001b[39m\u001b[34m(question, mode, top_k)\u001b[39m\n\u001b[32m     37\u001b[39m client = genai.Client(api_key=os.environ[\u001b[33m\"\u001b[39m\u001b[33mGEMINI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     38\u001b[39m config = types.GenerateContentConfig(temperature=\u001b[32m0.3\u001b[39m, max_output_tokens=\u001b[32m4096\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-3-flash-preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp.text \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, results\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\models.py:5215\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5213\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5214\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5215\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5216\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5217\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5219\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5220\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\models.py:3997\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3994\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   3995\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3997\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4002\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4003\u001b[39m ):\n\u001b[32m   4004\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1386\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1378\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1381\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1382\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1383\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1384\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1385\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m   response_body = (\n\u001b[32m   1388\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1389\u001b[39m   )\n\u001b[32m   1390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1219\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py:443\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\concurrent\\futures\\_base.py:395\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    397\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    398\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1199\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1192\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1193\u001b[39m       method=http_request.method,\n\u001b[32m   1194\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1197\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1198\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1200\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1201\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1202\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yotam\\Documents\\GitHub\\jerusalem_rag\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
            "\u001b[31mClientError\u001b[39m: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}"
          ]
        }
      ],
      "source": [
        "# Try different questions\n",
        "questions = [\n",
        "    \"Who was Baldwin IV of Jerusalem?\",\n",
        "    \"What were the laws of the Kingdom of Jerusalem?\",\n",
        "    \"How did Arabic sources describe the Crusaders?\",\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Q: {q}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    answer, sources = ask_question(q, top_k=4)\n",
        "    print(f\"\\nA: {answer[:500]}...\" if len(answer) > 500 else f\"\\nA: {answer}\")\n",
        "    print(f\"\\n[{len(sources)} sources used]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusion\n",
        "\n",
        "### Summary\n",
        "\n",
        "Jerusalem RAG Explorer demonstrates how RAG systems can:\n",
        "- **Bridge language barriers** through AI translation\n",
        "- **Enable semantic search** across historical documents\n",
        "- **Maintain scholarly rigor** through mandatory citations\n",
        "- **Reveal multiple perspectives** on historical events\n",
        "\n",
        "### Key Achievements\n",
        "\n",
        "1. **Multilingual Corpus**: Latin, Arabic, Greek, Armenian, French sources\n",
        "2. **Pre-translation Pipeline**: Non-English texts translated during ingestion\n",
        "3. **Semantic Retrieval**: FAISS index with 384-dim embeddings\n",
        "4. **Grounded Generation**: Every answer cites specific sources\n",
        "5. **Comparative Analysis**: Compare Eastern vs Western perspectives\n",
        "\n",
        "### Future Work\n",
        "\n",
        "- Fine-tune embeddings on medieval historical text\n",
        "- Add more sources (Vatican Library, British Library)\n",
        "- Implement hybrid search (BM25 + semantic)\n",
        "- Add citation verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**By Yotam Nachtomy-Katz** | ID: 211718366 | Haifa University | Information Retrieval Course | 01.02.26"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
